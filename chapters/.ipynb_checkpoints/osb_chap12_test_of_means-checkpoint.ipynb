{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 12 [Onlinestatsbook.com](onlinestatsbook.com) :  \"Test of Means\"\n",
    "------  \n",
    "\n",
    "\n",
    "#### Below are selected formulas and exercises from chapter 11 of the infamous onlinestatsbook.com, a highly trusted resource for learning about statistics.  \n",
    "\n",
    "#### The formulas and exercises were chosen based on difficulty and based on if using python to understand the concept or answer the question was deemed useful.\n",
    "\n",
    "#### Please note the below does not include the questions from the case studies.  A separate notebook for each case study can be found in this repository or is forthcoming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: \"Contents\"\n",
    "\n",
    "Many, if not most experiments are designed to compare means. The experiment may involve only one sample mean that is to be compared to a specific value. Or the experiment could be testing differences among many different experimental conditions, and the experimenter could be interested in comparing each mean with each of the other means. This chapter covers methods of comparing means in many different experimental situations.\n",
    "\n",
    "### Section 2: \"Testing a Single Mean\"\n",
    "\n",
    "we wish to know the probability of obtaining a sample mean of 51 **or more** when the sampling distribution of the mean has a mean of 50 and a standard deviation (standard error) of 1.667. Note this was calculated for us.  To compute this probability, we will make the assumption that the sampling distribution of the mean is normally distributed. Using the online statsbook normal calculator we can find out the probability is .274293. Here's the image:\n",
    "\n",
    "![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/tests_of_means/graphics/sig_mean1.gif\n",
    "\n",
    "We can also obtain this value with python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2742930981455225"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-stats.norm(50, 1.667).cdf(51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test conducted above was a one-tailed test because it computed the probability of a sample mean being one or more points higher than the hypothesized mean of 50 and the area computed was the area above 51.\n",
    "\n",
    "To test the two-tailed hypothesis, you would compute the probability of a sample mean differing by one or more in either direction from the hypothesized mean of 50. You would do so by computing the probability of a mean being less than or equal to 49 or greater than or equal to 51.  Here's what that looks like with the onlinestatsbook normal calc:\n",
    "\n",
    "![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/tests_of_means/graphics/sig_mean2.gif\n",
    "\n",
    "Here's how to calculate that in python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54858619629104499"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-stats.norm(50, 1.667).cdf(51))+stats.norm(50, 1.667).cdf(49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also leverage the survivial function which is 1-cdf to somewhat simplify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5485861962910451"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.norm(50, 1.667).sf(51)+ stats.norm(50, 1.667).cdf(49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically σ is not known and is estimated in a sample by s, and σM is estimated by sM. Using an example from the ADHD study, we test the null hypothesis is that the mean difference score in the population is 0 meaning the drug makes no difference.\n",
    "\n",
    "1.  calculate the t statistic using a special case of this formula:\n",
    "\n",
    "  ![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/tests_of_means/graphics/t_general.gif\n",
    "\n",
    "  ![alt text][img2]\n",
    "\n",
    "[img2]:http://onlinestatbook.com/2/tests_of_means/graphics/t_mean.gif\n",
    "\n",
    "where t is the value we compute for the significance test, M is the sample mean, μ is the hypothesized value of the population mean, and sM is the estimated standard error of the mean. \n",
    "\n",
    "2.  The mean (M) of the N = 24 difference scores is 4.958, the hypothesized value of μ is 0, and the standard deviation (s) is 7.538. obtain sM and calculate\n",
    "\n",
    "![alt text][img3]\n",
    "\n",
    "[img3]: http://onlinestatbook.com/2/tests_of_means/graphics/se1.gif\n",
    "\n",
    "Therefore, t = 4.96/1.54 = 3.22.\n",
    "\n",
    "3. Use t to calculate the shaded area.\n",
    "\n",
    "![alt text][img4]\n",
    "\n",
    "[img4]: http://onlinestatbook.com/2/tests_of_means/graphics/t_calc.gif\n",
    "\n",
    "\n",
    "This is rather easy to do with python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003792872940570291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-stats.t.cdf(3.22, df = 23))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 out of 9.\n",
    "You should do the test with Z rather than t when:\n",
    "\n",
    "answer: The numbers are sampled from a normal distribution.\n",
    "\n",
    "##### Question 2 out of 9.\n",
    "Assume you know the standard deviation of test scores is 10 and that the distribution is normal. You sample 16 scores and find that the sample mean is 25. Find the p value for a two-tailed test of the hypothesis that the population mean is 20. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045500263896358389"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to calculate the standard error of the mean\n",
    "std_err = 10/16**.5\n",
    "stats.norm(25, std_err).cdf(20)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3 out of 9.\n",
    "What is the standard deviation of these sample data?\n",
    "\n",
    "\n",
    "\n",
    "Y\n",
    " -2\n",
    "  1\n",
    "  3\n",
    "  2\n",
    " -1\n",
    "  0\n",
    "  4\n",
    "  6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6692695630078278"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray(list(map(int,\"-2 1 3 2 -1 0 4 6\".split())))\n",
    "x.std(ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4 out of 9.\n",
    "What is the estimated standard error of the mean based on these sample data? (These are the same data as the previous question.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94372930440884362"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.sem(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5 out of 9.\n",
    "What is the value of t testing the null hypothesis that the population mean is 0? (These are the same data as the previous question.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7218920641845572"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = x.mean()/stats.sem(x)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 out of 9.\n",
    "What is the two-tailed probability value testing the null hypothesis that the population mean is 0? (These are the same data as the previous question.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1287617132182699"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-stats.t.cdf(t, df = 7))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7 out of 9.\n",
    "Using these data below, what is the t statistic for a single-sample t test (null hypothesis is that μ = 0)\n",
    "\n",
    "Y\n",
    "  2.29\n",
    "  2.20\n",
    "  2.28\n",
    "  0.65\n",
    " -0.18\n",
    " -1.18\n",
    "  1.22\n",
    " -0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9368538470747008"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray(list(map(float,\"2.29 2.20 2.28 0.65 -0.18 -1.18 1.22 -0.07\".split())))\n",
    "x.mean()/stats.sem(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 8 out of 9.\n",
    "Using these data below, what is the t statistic for a single-sample t test (null hypothesis is that μ = .5)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8623163452302065"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.mean()-.5)/stats.sem(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 9 out of 9.\n",
    "Using these data below, what is the two-tailed p value for a single-sample t test (null hypothesis is that μ = .5)?\n",
    "\n",
    "Y\n",
    "  0.05\n",
    "  1.80\n",
    "  0.23\n",
    "  1.33\n",
    "  0.17\n",
    "  0.48\n",
    "  0.47\n",
    "  0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4932915965578788"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray(list(map(float,\"0.05 1.80 0.23 1.33 0.17 0.48 0.47 0.72\".split())))\n",
    "t = (x.mean()-.5)/stats.sem(x)\n",
    "(1-stats.t.cdf(t, df = len(x)-1))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: \"Difference between Two Means (Independent Groups)\"\n",
    "\n",
    "It is much more common for a researcher to be interested in the difference between means than in the specific values of the means themselves.  Here's a table of stats for two groups\n",
    "\n",
    "<div class=\"tableHolder300\">\n",
    "               <table>\n",
    "                <tbody><tr>\n",
    "                \t<th>\n",
    "                    \tGroup\n",
    "                    </th>\n",
    "                \t<th>\n",
    "                    \tn\n",
    "                    </th>\n",
    "                \t<th>\n",
    "                    \tMean\n",
    "                    </th>\n",
    "                \t<th>\n",
    "                    \tVariance\n",
    "                    </th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                \t<td>\n",
    "                    \tFemales\n",
    "                    </td>\n",
    "                \t<td>\n",
    "                    \t17\n",
    "                    </td>\n",
    "                \t<td>\n",
    "                    \t5.353\n",
    "                    </td>\n",
    "                \t<td>\n",
    "                    \t2.743\n",
    "                    </td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                \t<td>\n",
    "                    \tMales\n",
    "                    </td>\n",
    "                \t<td>\n",
    "                    \t17\n",
    "                    </td>\n",
    "                \t<td>\n",
    "                    \t3.882\n",
    "                    </td>\n",
    "                \t<td>\n",
    "                    \t2.985\n",
    "                    </td>\n",
    "                </tr>\n",
    "              </tbody></table>\n",
    "              </div>\n",
    "\n",
    "In order to test whether there is a difference between population means, we are going to make three assumptions:\n",
    "1.  The two populations have the same variance. This assumption is called the assumption of homogeneity of variance.\n",
    "2.  The populations are normally distributed.\n",
    "3.  Each value is sampled independently from each other value. This assumption requires that each subject provide only one value. If a subject provides two scores, then the scores are not independent. The analysis of data with two scores per subject is discussed later (correlated t test)\n",
    "\n",
    "**Note**: small-to-moderate violations of assumptions 1 and 2 do not make much difference. It is important not to violate assumption 3.\n",
    "\n",
    "\n",
    "As seen in the previous section:\n",
    "\n",
    "  ![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/tests_of_means/graphics/t_general.gif\n",
    "\n",
    "\n",
    "In this case, our statistic is the difference between sample means and our hypothesized value is 0. The hypothesized value is the null hypothesis that the difference between population means is 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = 5.353-3.882"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to compute the estimate of the standard error of the statistic. In this case, the statistic is the difference between means, so the estimated standard error of the statistic is (). Recall the formula for the standard error of the difference between means is:\n",
    "\n",
    "  ![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/sampling_distributions/graphics/equal_var.gif\n",
    "\n",
    "we estimate σ2 and use that estimate in place of σ2. Since we are assuming the two population variances are the same, we estimate this variance by averaging our two sample variances. Thus, our estimate of variance is\n",
    "\n",
    "  ![alt text][img2]\n",
    "\n",
    "[img2]:http://onlinestatbook.com/2/estimation/graphics/MSE.gif\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.864"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = (2.743 + 2.985)/2\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "therefore the standard error would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5804663439602578"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_err = ((2*mse)/17)**.5 #17 is the numer in each group\n",
    "std_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and t is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.534169319730126"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = diff/std_err\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we compute the probability of getting a t as large or larger than 2.533 or as small or smaller than -2.533. To do this, we need to know the degrees of freedom. The degrees of freedom is the number of independent estimates of variance on which MSE is based. This is equal to (n1 - 1) + (n2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 17*2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see below from onlinstatbook t distribution calculator that the probability value for a two-tailed test with t = t and df = df is 0.0164\n",
    "\n",
    "  ![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/tests_of_means/graphics/t_prob_2-tail.gif\n",
    "\n",
    "We can also compute this fairly easily in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016199890812905293"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-stats.t.cdf(t,df))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computations for Unequal Sample Sizes (optional)\n",
    "\n",
    "Problem with above is that MSE, the estimate of variance, counts the group with the larger sample size more than the group with the smaller sample size. \n",
    "\n",
    "for group_a = [3,4,5] and group_b = [2,4]:\n",
    "\n",
    "  * M1 = 4 and M2 = 3\n",
    "\n",
    "  * SSE = (3-4)2 + (4-4)2 + (5-4)2 + (2-3)2 + (4-3)2 = 4\n",
    "\n",
    "Then, MSE is computed by: \n",
    "\n",
    "   * MSE = SSE/df\n",
    "\n",
    "where the degrees of freedom (df) is computed as before: \n",
    "\n",
    "  * df = (n1 - 1) + (n2 - 1) = (3 - 1) + (2 - 1) = 3. \n",
    "  * MSE = SSE/df = 4/3 = 1.333.\n",
    "  \n",
    "the formula for the standard error is replaced by:\n",
    "\n",
    "  ![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/estimation/graphics/sed_uneq.gif\n",
    "\n",
    "where nh is the harmonic mean of the sample sizes and is calculated as follows:\n",
    "\n",
    "  ![alt text][img2]\n",
    "\n",
    "[img2]:http://onlinestatbook.com/2/estimation/graphics/nh.gif   \n",
    "\n",
    "\n",
    "Therefore the replacement for the stantard error is  = 1.054 and:\n",
    "\n",
    "\n",
    "  * t = (4-3)/1.054 = 0.949\n",
    "\n",
    "  * and the two-tailed p = 0.413.\n",
    "  \n",
    "  \n",
    "##### Question 8 out of 9.\n",
    "If there are 4 scores per group and the t value is 2.34, what is the p value for a two-tailed test (to 3 decimal places)? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057843940267015004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-stats.t.cdf(2.34,6))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 9 out of 9.\n",
    "What is the t for an independent-groups t test for these data? \n",
    "\n",
    "\n",
    "\n",
    "  G 1\t  G 2\n",
    " 54\t 44\n",
    " 39\t 47\n",
    " 40\t 45\n",
    " 45\t 30\n",
    " 56\t 38\n",
    " 51\t 17\n",
    " 67\t 37\n",
    " 48\t 53\n",
    " \n",
    " note:  this data is displaying funky.  every other number is in a separate group.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54, 44, 39, 47, 40, 45, 45, 30, 56, 38, 51, 17, 67, 37, 48, 53]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(map(int,\"54 44 39 47 40 45 45 30 56 38 51 17 67 37 48 53\".split()))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 39, 40, 45, 56, 51, 67, 48]\n",
      "[44, 47, 45, 30, 38, 17, 37, 53]\n"
     ]
    }
   ],
   "source": [
    "g_a = []\n",
    "g_b = []\n",
    "for i in range(0,len(x)):\n",
    "    if i%2==0:\n",
    "        g_a.append(x[i])\n",
    "    else:\n",
    "        g_b.append(x[i])\n",
    "print(g_a)\n",
    "print(g_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1619306640686724"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.mean(g_a)-np.mean(g_b)\n",
    "mse = (np.var(g_a, ddof=1) + np.var(g_b, ddof=1))/2\n",
    "std_err = ((2*mse)/len(g_a))**.5\n",
    "t = diff/std_err\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6: \"All Pairwise Comparisons Among Means\"\n",
    "\n",
    "Many experiments are designed to compare more than two conditions. An obvious way to proceed would be to do a t test of the difference between each group mean and each of the other group means. The problem with this approach is that if you did this analysis, you would have six chances to make a Type I error. The more means that are compared, the more the Type I error rate is inflated. Figure 1 shows the number of possible comparisons between pairs of means (pairwise comparisons) as a function of the number of means. \n",
    "\n",
    "  ![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/tests_of_means/graphics/number_of_comparisons.gif\n",
    "\n",
    "The figure below shows the probability of a Type I error as a function of the number of means. \n",
    "\n",
    "  ![alt text][img2]\n",
    "\n",
    "[img2]:http://onlinestatbook.com/2/tests_of_means/graphics/familywise.gif\n",
    "\n",
    "\n",
    "The probability of a type I error rate is high even for a small number of means.  The Type I error rate can be controlled using a test called the **Tukey Honestly Significant Difference test or Tukey HSD** for short. The Tukey HSD is based on a variation of the t distribution that takes into account the number of means being compared. This distribution is called the **studentized range distribution.**\n",
    "\n",
    "Note:  The assumptions of the Tukey test are essentially the same as for an independent-groups t test: normality, homogeneity of variance, and independent observations. The test is quite robust to violations of normality. Violating homogeneity of variance can be more problematical than in the two-sample case since the MSE is based on data from all groups. The assumption of independence of observations is important and should not be violated.\n",
    "\n",
    "Using the leniency study we will do an example using the data below:\n",
    "\n",
    "<table>\n",
    "  <tbody><tr>\n",
    "   <th>\n",
    "                        \tCondition\n",
    "                        </th>\n",
    "                        <th> \n",
    "                        \tMean\n",
    "                        </th>\n",
    "                        <th> \n",
    "                        \tVariance\n",
    "                        </th>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                        \tFalse\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t5.37\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t3.34\n",
    "                        </td>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                        \tFelt\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t4.91\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t2.83\n",
    "                        </td>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                       \t\tMiserable\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t4.91\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t2.11\n",
    "                        </td>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                        \tNeutral\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t4.12\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t2.32\n",
    "                        </td>\n",
    "                      </tr>\n",
    "              </tbody></table>\n",
    "\n",
    "1.  Compute MSE, which is simply the mean of the variances. It is equal to 2.65.\n",
    "\n",
    "2.  Compute Q:\n",
    "\n",
    "  ![alt text][img3]\n",
    "\n",
    "[img3]:http://onlinestatbook.com/2/tests_of_means/graphics/ts_form.gif\n",
    "\n",
    "   for each pair of means, where Mi is one mean, Mj is the other mean, and n is the number of scores in each group. For these data, there are 34 observations per group. The value in the denominator is 0.279.\n",
    "   \n",
    "   \n",
    "3.  Compute p for each comparison using the Studentized Range Calculator. The degrees of freedom is equal to the total number of observations minus the number of means. For this experiment, df = 136 - 4 = 132.\n",
    "\n",
    "<table>\n",
    "               \t\t <tbody><tr>\n",
    "                        <th>\n",
    "                        \tComparison\n",
    "                        </th>\n",
    "                        <th> \n",
    "                        \tM<sub>i</sub>-M<sub>j</sub>\n",
    "                        </th>\n",
    "                        <th> \n",
    "                        \tQ\n",
    "                        </th>\n",
    "                        <th> \n",
    "                        \tp\n",
    "                        </th>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                        \tFalse - Felt\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.46\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t1.65\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.649\n",
    "                        </td>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                        \tFalse - Miserable\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.46\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t1.65\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.649\n",
    "                        </td>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                       \t\t False - Neutral\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t1.25\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t4.48\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.010\n",
    "                        </td>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                        \tFelt - Miserable\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.00\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.00\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t1.000\n",
    "                        </td>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                        \tFelt - Neutral\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.79\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t2.83\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.193\n",
    "                        </td>\n",
    "                      </tr>\n",
    "                      <tr> \n",
    "                        <td> \n",
    "                        \tMiserable - Neutral\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.79\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t2.83\n",
    "                        </td>\n",
    "                        <td> \n",
    "                        \t0.193\n",
    "                        </td>\n",
    "                      </tr>\n",
    "              </tbody></table>\n",
    "      \n",
    "The only significant comparison is between the false smile and the neutral smile.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tukey for Unequal Sample Sizes (optional)\n",
    "The calculation of MSE for unequal sample sizes is similar to its calculation in an independent-groups t test. Here are the steps:\n",
    "\n",
    "1. Compute a Sum of Squares Error (SSE) using the following formula  \n",
    "\n",
    "   ![alt text][img1]\n",
    "   [img1]:http://onlinestatbook.com/2/tests_of_means/graphics/SSE.gif\n",
    "    where Mi is the mean of the ith group and k is the number of groups. \n",
    "\n",
    "2. Compute the degrees of freedom error (dfe) by subtracting the number of groups (k) from the total number of observations (N). Therefore, dfe = N - k.\n",
    "\n",
    "3.  Compute MSE by dividing SSE by dfe: MSE = SSE/dfe.\n",
    "\n",
    "4.  For each comparison of means, use the harmonic mean of the n's for the two means (nh).\n",
    "\n",
    "All other aspects of the calculations are the same as when you have equal sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4 out of 7.\n",
    "Assume you did an experiment with 3 groups and 16 subjects per group. The sample variances in the three groups were 14, 16, and 18. The value of MSE would be\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([14, 16, 18])/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5 out of 7.\n",
    "Assume you did an experiment with 3 groups and 16 subjects per group. The sample variances in the three groups were 14, 16, and 18. Using Tukey's test to compare the means, what would be the value of Q for a comparison of the first mean (14) with the last mean (18)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14-18/(16/16)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 out of 7.\n",
    "Assume you did an experiment with 3 groups and 16 subjects per group. The sample variances in the three groups were 14, 16, and 18. Using Tukey's test to compare the means, what would be the df for the test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*3-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 7 out of 7.\n",
    "Assume you did an experiment with 3 groups and 16 subjects per group. The sample variances in the three groups were 14, 16, and 18. Using Tukey's test to compare the means, what would be the two-tailed probability for a comparison of the first mean (14) with the last mean (18)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018714290629434527"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.libqsturng import psturng\n",
    "mse = (14+16+18)/3\n",
    "q = (18-14)/((mse/16)**.5)\n",
    "n = 3\n",
    "df = 45\n",
    "psturng(q,n,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 7: \"Specific Comparisons (Independent Groups)\"\n",
    "\n",
    "This section shows how to test more complex comparisons in which the comparisons among means are more complicated than simply comparing one mean with another.\n",
    "\n",
    "The methods in this section assume that the comparison among means was decided on before looking at the data. Therefore these comparisons are called planned comparisons. A different procedure is necessary for unplanned comparisons.\n",
    "\n",
    "**An Example:** Twelve subjects were selected from a population of high-self-esteem subjects (esteem = 1) and an additional 12 subjects were selected from a population of low-self-esteem subjects (esteem = 2). Subjects then performed on a task and (independent of how well they really did) half in each esteem category were told they succeeded (outcome = 1) and the other half were told they failed (outcome = 2). Therefore, there were six subjects in each of the four esteem/outcome combinations and 24 subjects in all. After the task, subjects were asked to rate (on a 10-point scale) how much of their outcome (success or failure) they attributed to themselves as opposed to being due to the nature of the task.  The means of the four conditions:\n",
    "\n",
    "| Outcome       | Esteem           | Mean  |\n",
    "| ------------- |:----------------:| -----:|\n",
    "| Success       | High Self-Esteem | 7.333 |\n",
    "|               | Low Self-Esteem  | 5.500 |\n",
    "| Failure       | High Self-Esteem | 4.833 |\n",
    "|               | Low Self-Esteem  | 7.833 |\n",
    "\n",
    "We begin by asking whether, on average, subjects who were told they succeeded differed significantly from subjects who were told they failed. The means of each condition are 6.4167 and 6.3333 but how do we do a significance test for theis difference .083?\n",
    "\n",
    "**express this difference in terms of a _linear combination_ using a set of coefficients and the means.**  So...\n",
    "\n",
    "compute the mean of the success conditions by multiplying each success mean by 0.5 and then adding the result.  \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;(.5)(7.333) + (.5)(5.500) = the mean of the success condition 6.42.\n",
    "\n",
    "It's just another way of computing the mean.  It follows that the difference between the two means can be expressed as:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; .5 x 7.333 + .5 x 5.500 -(.5 x 4.833 + .5 x 7.833)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; = L = 3.667 + 2.750 - 2.417 - 3.917 = 0.083\n",
    "\n",
    "We therefore can compute the difference between the \"success\" mean and the \"failure\" mean by multiplying each \"success\" mean by 0.5, each failure mean by -0.5, and adding the results. \n",
    "\n",
    "Now, the question is whether our value of L is significantly different from 0. The general formula for L is:\n",
    "\n",
    "![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/tests_of_means/graphics/L1.gif\n",
    "\n",
    "where ci is the ith coefficient and Mi is the ith mean. As shown above, L = 0.083. The formula for testing L for significance is shown below:\n",
    "\n",
    "![alt text][img2]\n",
    "\n",
    "[img2]:http://onlinestatbook.com/2/tests_of_means/graphics/L.gif\n",
    "\n",
    "In this example:\n",
    "\n",
    "![alt text][img3]\n",
    "\n",
    "[img3]:http://onlinestatbook.com/2/tests_of_means/graphics/c.gif\n",
    "\n",
    "MSE is the mean of the variances for each of the four groups.  The value of n is the number of subjects in each group. So...\n",
    "\n",
    "![alt text][img4]\n",
    "\n",
    "[img4]:http://onlinestatbook.com/2/tests_of_means/graphics/tl1.gif\n",
    "\n",
    "since df = N - k...\n",
    "\n",
    "We can use the t distribution\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87448598982479497"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-stats.t.cdf(.16,20))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two tailed probability is .874 so we can say the difference between the success condition is not significant.\n",
    "\n",
    "A more interesting question about the results is whether the effect of outcome (success or failure) differs depending on the self-esteem of the subject. For example, success may make high-self-esteem subjects more likely to attribute the outcome to themselves, whereas success may make low-self-esteem subjects less likely to attribute the outcome to themselves.\n",
    "\n",
    "To test this, we have to test a difference between differences. Specifically, is the difference between success and failure outcomes for the high-self-esteem subjects different from the difference between success and failure outcomes for the low-self-esteem subjects? The coefficients to test this difference between differences are shown in Table:\n",
    "\n",
    "Table 5. Coefficients for testing difference between differences.  \n",
    "\n",
    "|Self-Esteem|Outcome|Mean  |Coeff|Product|\n",
    "|-----------|-------|------|-----|-------|\n",
    "|High       |Success|7.333 |1    |7.333  |\n",
    "|           |Failure|4.833 |-1    |-4.833 |\n",
    "|Low        |Success|5.500 |-1    |-5.500  |\n",
    "|           |Failure|7.833 |1    |7.833  |\n",
    "\n",
    "If it is hard to see where these coefficients came from, consider that our difference between differences was computed this way:  \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(7.33 - 4.83) - (5.50 - 7.83)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= 7.33 - 4.83 - 5.50 + 7.83\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= (1)7.33 + (-1)4.83 + (-1)5.50 + (1)7.83\n",
    "\n",
    "The values in parentheses are the coefficients.\n",
    "\n",
    "To continue the calculations...\n",
    "\n",
    "L = 4.83 (the difference bw the differences)\n",
    "\n",
    "The sume of the squared coefficients is...\n",
    "\n",
    "![alt text][img1]\n",
    "\n",
    "[img1]:http://onlinestatbook.com/2/tests_of_means/graphics/c2.gif\n",
    "\n",
    "And....t is equal to...\n",
    "\n",
    "![alt text][img2]\n",
    "\n",
    "[img2]: http://onlinestatbook.com/2/tests_of_means/graphics/tl2.gif\n",
    "\n",
    "And computing the two tailed probability in python:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00015795741947521869"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-stats.t.cdf(4.64,20))*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is highly significant.\n",
    "\n",
    "**note**: comparisons such as this are testing what is called an interaction. In general, there is an interaction when the effect of one variable differs as a function of the level of another variable. this will be studied later.  In this example, the effect of the outcome variable is different depending on the subject's self-esteem. For the high-self-esteem subjects, success led to more self-attribution than did failure; for the low-self-esteem subjects, success led to less self-attribution than did failure.\n",
    "\n",
    "\n",
    "#### Multiple Comparisons\n",
    "\n",
    "The more comparisons you make, the greater your chance of a Type I error.  The per-comparison error rate is the probability of a Type I error for a particular comparison and is equal to alpha for each individual comparison. The familywise error rate is the probability of making one or more Type I errors in a family or set of comparisons and we can use the bonferrone inequality to approximate it.  \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Familywise error rate(FW) ≤ cα\n",
    "\n",
    "\n",
    "c is the number of comparisons.  \n",
    "\n",
    "The Bonferroni inequality can be used to control the familywise error rate as follows: If you want the familywise error rate to be α, you use α/c as the per-comparison error rate. This correction, called the Bonferroni correction, will generally result in a familywise error rate less than α. Alternatively, you could multiply the probability value by c and use the original α level.\n",
    "\n",
    "\n",
    "he disadvantage of controlling the familywise error rate is that it makes it more difficult to obtain a significant result for any given comparison: The more comparisons you do, the lower the per-comparison rate must be and therefore the harder it is to reach significance. That is, the power is lower when you control the familywise error rate. The advantage is that you have a lower chance of making a Type I error.\n",
    "\n",
    "THis section has some nice examples further fleshing it out.  \n",
    "\n",
    "#### Orthogonal Comparisons\n",
    "\n",
    "In the preceding sections, we talked about comparisons being independent. Independent comparisons are often called orthogonal comparisons. There is a simple test to determine whether two comparisons are orthogonal: If the sum of the products of the coefficients is 0, then the comparisons are orthogonal. Here the products are orthogonal:\n",
    "\n",
    "|Self-Esteem|Outcome|Mean  |Coeff|Product|\n",
    "|-----------|-------|------|-----|-----|\n",
    "|Success    |High Esteem | .5 |1    |.5   |\n",
    "|           |Low Esteem | .5 |-1    |-.5  |\n",
    "|Failure    |High Esteem | -.5 |-1    |.5 |\n",
    "|           |Low Esteem | -.5 |1    |-.5  |\n",
    "\n",
    "Here they are not because the sum of the products is =.5 not 0:\n",
    "\n",
    "|Self-Esteem|Outcome|Mean  |Coeff|Product|\n",
    "|-----------|-------|------|-----|-----|\n",
    "|Success    |High Esteem | .5 |.5    |.25  |\n",
    "|           |Low Esteem | .5 |.5    |.25  |\n",
    "|Failure    |High Esteem | -.5 |0    |0 |\n",
    "|           |Low Esteem | -.5 |0   |0  |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 out of 6.\n",
    "You plan to test all pairwise comparisons among 4 means. What is the new critical p value after a Bonferroni adjustment to maintain an experiment-wise alpha of .05?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008333333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".05/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3 out of 6.\n",
    "What coefficients would be used to compare Group 1 to the average of Groups 2-4? \n",
    "\n",
    "Answer: 1, -.333, -.333, -.333\n",
    "\n",
    "##### Question 4 out of 6.\n",
    "In an experiment with three conditions, the means are 2, 4, and 9. What would be the value of L for the coefficients 2, -1, -1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*2+4*-1+9*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5 out of 6.\n",
    "Are the following two sets of coefficients orthogonal? \n",
    "\n",
    "-1, 0, 0, 1  \n",
    "-1, 1, 0, 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*-1+0*1+0*0+0*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 out of 6.\n",
    "In an experiment with three conditions and 5 subjects per condition, the means are 2, 4, and 9, and the MSE is 24. \n",
    "\n",
    "Find t for the coefficients -2, 1, 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6770509831248424"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = -2*2+1*4+1*9\n",
    "den = (((4+1+1)*24)/5)**.5\n",
    "L/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 9: \"Difference Between Two Means (Correlated Pairs)\"\n",
    "\n",
    "What do we do when we dont have independent groups.  For example with the ADHD study, they tested the whole group under four conditions not four groups under different conditions each.\n",
    "\n",
    "\n",
    "A correlated t-test is computed by first computing the difference between the two scores for each subject, calculating the mean and test whether the mean difference is significantly different from 0. \n",
    "\n",
    "If we used an independent t-test the difference between means would not have been found to be statistically significant. This is a typical result: correlated t tests almost always have greater power than independent-groups t tests. This is because in correlated t tests, each difference score is a comparison of performance in one condition with the performance of that same subject in another condition. This makes each subject \"their own control\" and keeps differences between subjects from entering into the analysis. The result is that the standard error of the difference between means is smaller in the correlated t test and, since this term is in the denominator of the formula for t, results in a larger t.\n",
    "\n",
    "NOte: Skipped mathematics on why the stand error is lower as well as the exercised for this section.  In general for correlated pairs, the variance is the sum of the variances minus two times the product of the correlation and the standard deviation of each.\n",
    "\n",
    "### Section 10: \"Specific Comparisons (Correlated Observations)\"\n",
    "\n",
    "Note: Skipped section 10\n",
    "\n",
    "### Section 11:  Pairwise Comparisons (Correlated Observations)\n",
    "\n",
    "For pairwise comparisons among independent groups, the Tukey HSD test was the recommended procedure. However, when you have one group with several scores from the same subjects, the Tukey test makes an assumption that is unlikely to hold: The variance of difference scores is the same for all pairwise differences between means.\n",
    "\n",
    "The standard practice for pairwise comparisons with correlated observations is to compare each pair of means using the method outlined in the section \"Difference Between Two Means (Correlated Pairs)\" with the addition of the Bonferroni correction\n",
    "\n",
    "For example, suppose you were going to do all pairwise comparisons among four means and hold the familywise error rate at 0.05. Since there are six possible pairwise comparisons among four means, you would use 0.05/6 = 0.0083 for the per-comparison error rate.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "##### Q1: The scores of a random sample of 8 students on a physics test are as follows: 60, 62, 67, 69, 70, 72, 75, and 78.  \n",
    "a.  Test to see if the sample mean is significantly different from 65 at the .05 level. Report the t and p values.  \n",
    "b.  The researcher realizes that she accidentally recorded the score that should have been 76 as 67. Are these corrected scores significantly different from 65 at the .05 level? (relevant section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t is 1.9111806309\n",
      "p is 0.0976138663502\n"
     ]
    }
   ],
   "source": [
    "#a\n",
    "nums = np.array([60, 62, 67, 69, 70, 72, 75, 78])\n",
    "s_M = nums.std(ddof=1)/len(nums)**.5\n",
    "print(\"t is \"+str((nums.mean()-65)/s_M))\n",
    "print(\"p is \"+str((1-stats.t.cdf(1.911, df = len(nums)-1))*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t is 2.2932387102\n",
      "p is 0.0555613134774\n"
     ]
    }
   ],
   "source": [
    "#b\n",
    "nums = np.array([60, 62, 76, 69, 70, 72, 75, 78])\n",
    "s_M = nums.std(ddof=1)/len(nums)**.5\n",
    "print(\"t is \"+str((nums.mean()-65)/s_M))\n",
    "print(\"p is \"+str((1-stats.t.cdf(2.293, df = len(nums)-1))*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2 A (hypothetical) experiment is conducted on the effect of alcohol on perceptual motor ability. Ten subjects are each tested twice, once after having two drinks and once after having two glasses of water. The two tests were on two different days to give the alcohol a chance to wear off. Half of the subjects were given alcohol first and half were given water first. The scores of the 10 subjects are shown below. The first number for each subject is their performance in the \"water\" condition. Higher scores reflect better performance. Test to see if alcohol had a significant effect. Report the t and p values. (relevant section)\n",
    "\n",
    "\n",
    "water\n",
    "alcohol\n",
    "16\n",
    "13\n",
    "15\n",
    "13\n",
    "11\n",
    "10\n",
    "20\n",
    "18\n",
    "19\n",
    "17\n",
    "14\n",
    "11\n",
    "13\n",
    "10\n",
    "15\n",
    "15\n",
    "14\n",
    "11\n",
    "16\n",
    "16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 15 11 20 19 14 13 15 14 16]\n",
      "[13 13 10 18 17 11 10 15 11 16]\n"
     ]
    }
   ],
   "source": [
    "nums = list(map(int,\"16 13 15 13 11 10 20 18 19 17 14 11 13 10 15 15 14 11 16 16\".split()))\n",
    "\n",
    "water = []\n",
    "alchohol = []\n",
    "\n",
    "for i in range(0,len(nums)):\n",
    "    if i%2==0:\n",
    "        water.append(nums[i])\n",
    "    else:\n",
    "        alchohol.append(nums[i])\n",
    "        \n",
    "water = np.array(water)\n",
    "alchohol = np.array(alchohol)\n",
    "\n",
    "print(water)\n",
    "print(alchohol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=5.0185701660560547, pvalue=0.00072049133854553316)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first the easy way\n",
    "stats.ttest_rel(water,alchohol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 5.01857016606\n",
      "p = 0.000720491338545\n"
     ]
    }
   ],
   "source": [
    "#now more manually to check accuracy\n",
    "diff = water - alchohol\n",
    "t = diff.mean()/stats.sem(diff)\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \"+str((1-stats.t.cdf(t, df = len(diff)-1))*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3 The scores on a (hypothetical) vocabulary test of a group of 20 year olds and a group of 60 year olds are shown below. \n",
    "\n",
    "\n",
    "20 yr olds\n",
    "60 yr olds\n",
    "27\n",
    "26\n",
    "26\n",
    "29\n",
    "21\n",
    "29\n",
    "24\n",
    "29\n",
    "15\n",
    "27\n",
    "18\n",
    "16\n",
    "17\n",
    "20\n",
    "12\n",
    "27\n",
    "13\n",
    "\n",
    "\n",
    "a.  Test the mean difference for significance using the .05 level. (relevant section).  \n",
    "b.  List the assumptions made in computing your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27 26 21 24 15 18 17 12 13]\n",
      "[26 29 29 29 27 16 20 27]\n"
     ]
    }
   ],
   "source": [
    "# setup the data\n",
    "nums = list(map(int,\"27 26 26 29 21 29 24 29 15 27 18 16 17 20 12 27 13\".split()))\n",
    "\n",
    "younger = []\n",
    "older = []\n",
    "\n",
    "for i in range(0,len(nums)):\n",
    "    if i%2==0:\n",
    "        younger.append(nums[i])\n",
    "    else:\n",
    "        older.append(nums[i])\n",
    "        \n",
    "younger = np.array(younger)\n",
    "older = np.array(older)\n",
    "\n",
    "print(younger)\n",
    "print(older)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 2.42364228799\n",
      "p = 0.0284764860044\n"
     ]
    }
   ],
   "source": [
    "#A\n",
    "# calculation is done differently for diff sample sizes and diff variance.\n",
    "# first we do it manually\n",
    "sse = sum((younger-younger.mean())**2)+sum((older-older.mean())**2) #sum of sum of square errors both samples\n",
    "df = len(younger)+len(older)-2 #degrees of freedom\n",
    "mse = sse/df #mean square error\n",
    "harmonic_mean = 2/(1/len(younger) +1/len(older)) #calc harmonic mean of sample sizes\n",
    "std_err = ((2*mse)/harmonic_mean)**.5 #calculate the std error differently than for equal sample sizes\n",
    "t = abs((younger.mean()-older.mean()))/std_err #calculate t\n",
    "p = (1-stats.t.cdf(t,df))*2\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \"+str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = -2.44572278434\n",
      "p = 0.0272750460293\n"
     ]
    }
   ],
   "source": [
    "#now the easy way\n",
    "t, p = stats.ttest_ind(younger,older, equal_var=False)\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \"+str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4 The sampling distribution of a statistic is normally distributed with an estimated standard error of 12 (df = 20). (a) What is the probability that you would have gotten a mean of 107 (or more extreme) if the population parameter were 100? Is this probability significant at the .05 level (two-tailed)? (b) What is the probability that you would have gotten a mean of 95 or less (one-tailed)? Is this probability significant at the .05 level? You may want to use the t Distribution calculator for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27983446359970576"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "1-stats.norm(100,12).cdf(107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33846111951068963"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "stats.norm(100,12).cdf(95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5 How do you decide whether to use an independent groups t test or a correlated t test (test of dependent means)? \n",
    "\n",
    "Answer: when the groups are not independent you use a correlated t test.  i.e. within groups.\n",
    "\n",
    "##### Q6  An experiment compared the ability of three groups of subjects to remember briefly-presented chess positions. The data are shown below. \n",
    "\n",
    "\n",
    "Non-players\n",
    "Beginners\n",
    "Tournament players\n",
    "22.1\n",
    "32.5\n",
    "40.1\n",
    "22.3\n",
    "37.1\n",
    "45.6\n",
    "26.2\n",
    "39.1\n",
    "51.2\n",
    "29.6\n",
    "40.5\n",
    "56.4\n",
    "31.7\n",
    "45.5\n",
    "58.1\n",
    "33.5\n",
    "51.3\n",
    "71.1\n",
    "38.9\n",
    "52.6\n",
    "74.9\n",
    "39.7\n",
    "55.7\n",
    "75.9\n",
    "43.2\n",
    "55.9\n",
    "80.3\n",
    "43.2\n",
    "57.7\n",
    "85.3\n",
    "\n",
    "a. Using the Tukey HSD procedure, determine which groups are significantly different from each other at the .05 level. (relevant section)\n",
    "\n",
    "b. Now compare each pair of groups using t-tests. Make sure to control for the familywise error rate (at 0.05) by using the Bonferroni correction. Specify the alpha level you used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22.1  22.3  26.2  29.6  31.7  33.5  38.9  39.7  43.2  43.2]\n",
      "[ 32.5  37.1  39.1  40.5  45.5  51.3  52.6  55.7  55.9  57.7]\n",
      "[ 40.1  45.6  51.2  56.4  58.1  71.1  74.9  75.9  80.3  85.3]\n"
     ]
    }
   ],
   "source": [
    "#first prepare the data\n",
    "\n",
    "nums = list(map(float,\"22.1 32.5 40.1 22.3 37.1 45.6 26.2 39.1 51.2 29.6 40.5 56.4 31.7 45.5 58.1 33.5 51.3 71.1 38.9 52.6 74.9 39.7 55.7 75.9 43.2 55.9 80.3 43.2 57.7 85.3\".split()))\n",
    "non_players = []\n",
    "beginners = []\n",
    "tourney_players = []\n",
    "for i in range(0,len(nums)):\n",
    "    if (i+3)%3==0:\n",
    "        non_players.append(nums[i])\n",
    "    elif(i+3)%3==1:\n",
    "        beginners.append(nums[i])\n",
    "    else:\n",
    "        tourney_players.append(nums[i])\n",
    "        \n",
    "non_players = np.array(non_players)\n",
    "beginners = np.array(beginners)\n",
    "tourney_players =np.array(tourney_players)\n",
    "\n",
    "print(non_players)\n",
    "print(beginners)\n",
    "print(tourney_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_players-beginners=  0.0180708489014\n",
      "non_players-tourney_players=  0.001\n",
      "beginners-tourney_players=  0.00270618499686\n"
     ]
    }
   ],
   "source": [
    "#imported psturng above\n",
    "mse = (non_players.var() + beginners.var() + tourney_players.var())/3\n",
    "n = 3\n",
    "df = 3*len(non_players)-3\n",
    "df = 45\n",
    "\n",
    "import itertools \n",
    "arrays = [\"non_players\", \"beginners\", \"tourney_players\"]\n",
    "combos = list(itertools.combinations(arrays,2))\n",
    "count = 0\n",
    "for x,y in itertools.combinations([non_players, beginners, tourney_players],2):\n",
    "    q = abs(x.mean()-y.mean())/((mse/len(x))**.5)\n",
    "    print(combos[count][0]+\"-\"+combos[count][1] + \"=  \" +str(psturng(q,n,df)))\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Multiple Comparison of Means - Tukey HSD,FWER=0.05     \n",
      "============================================================\n",
      "   group1        group2     meandiff  lower    upper  reject\n",
      "------------------------------------------------------------\n",
      " beginners    non_players    -13.75  -26.3921 -1.1079  True \n",
      " beginners  tourney_players   17.1    4.4579  29.7421  True \n",
      "non_players tourney_players  30.85   18.2079  43.4921  True \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#check with statsmodels\n",
    "data = pd.DataFrame({\"non_players\":non_players, \"beginners\":beginners, \"tourney_players\": tourney_players})\n",
    "data = data.melt()  #statsmodels requires it in a certain format\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "posthoc = pairwise_tukeyhsd(\n",
    "    data['value'], data['variable'],\n",
    "    alpha=0.05)\n",
    "print(posthoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Test Multiple Comparison ttest_ind \n",
       "FWER=0.05 method=Bonferroni\n",
       "alphacSidak=0.02, alphacBonf=0.017</caption>\n",
       "<tr>\n",
       "    <th>group1</th>        <th>group2</th>       <th>stat</th>    <th>pval</th>  <th>pval_corr</th> <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>beginners</td>    <td>non_players</td>   <td>3.5975</td>  <td>0.0021</td>  <td>0.0062</td>    <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>beginners</td>  <td>tourney_players</td> <td>-2.9969</td> <td>0.0077</td>  <td>0.0232</td>    <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>non_players</td> <td>tourney_players</td> <td>-5.5537</td>   <td>0.0</td>   <td>0.0001</td>    <td>True</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "mod = MultiComparison(data['value'], data['variable'])\n",
    "rtp = mod.allpairtest(stats.ttest_ind, method=\"Bonferroni\")\n",
    "rtp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
